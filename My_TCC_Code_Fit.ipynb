{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importar de Bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "import seaborn as sn\n",
    "from IPython.display import Image, display\n",
    "from PIL import Image as Imagem\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import copy\n",
    "import time\n",
    "from datetime import timedelta\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Verificação das Versões"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importar funções e classes provenientes dos arquivos inception.py e knifey.py\n",
    "As funções e classes knifey e inception irão nos auxiliar ao tentarmos dividir o dataset em clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import knifey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "knifey.data_dir = \"data/movedataset/\"\n",
    "data_dir = knifey.data_dir\n",
    "dataset = knifey.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = dataset.class_names\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths_train, cls_train, labels_train = dataset.get_training_set()\n",
    "image_paths_test, cls_test, labels_test = dataset.get_test_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print (image_paths_train[0])\n",
    "print (image_paths_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dimensões:\")\n",
    "print(\"- Dados de Treino:\\t\\t{}\".format(len(image_paths_train)))\n",
    "print(\"- Dados de Teste:\\t\\t{}\".format(len(image_paths_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função Auxiliar para Mostrar as Imagens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função usada para mostrar 9 imagens em um\n",
    "a tabela 3x3 e escrever o valor real e a predição abaixo de cada imagem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(images, cls_true, cls_pred=None, smooth=True):\n",
    "\n",
    "    assert len(images) == len(cls_true)\n",
    "\n",
    "    # Create figure with sub-plots.\n",
    "    fig, axes = plt.subplots(3, 3)\n",
    "\n",
    "    # Adjust vertical spacing.\n",
    "    if cls_pred is None:\n",
    "        hspace = 0.3\n",
    "    else:\n",
    "        hspace = 0.6\n",
    "    fig.subplots_adjust(hspace=hspace, wspace=0.3)\n",
    "\n",
    "    # Interpolation type.\n",
    "    if smooth:\n",
    "        interpolation = 'spline16'\n",
    "    else:\n",
    "        interpolation = 'nearest'\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        # There may be less than 9 images, ensure it doesn't crash.\n",
    "        if i < len(images):\n",
    "            # Plot image.\n",
    "            ax.imshow(images[i],\n",
    "                      interpolation=interpolation)\n",
    "\n",
    "            # Name of the true class.\n",
    "            cls_true_name = class_names[cls_true[i]]\n",
    "\n",
    "            # Show true and predicted classes.\n",
    "            if cls_pred is None:\n",
    "                xlabel = \"True: {0}\".format(cls_true_name)\n",
    "            else:\n",
    "                # Name of the predicted class.\n",
    "                cls_pred_name = class_names[cls_pred[i]]\n",
    "\n",
    "                xlabel = \"True: {0}\\nPred: {1}\".format(cls_true_name, cls_pred_name)\n",
    "\n",
    "            # Show the classes as the label on the x-axis.\n",
    "            ax.set_xlabel(xlabel)\n",
    "        \n",
    "        # Remove ticks from the plot.\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    \n",
    "    # Ensure the plot is shown correctly with multiple plots\n",
    "    # in a single Notebook cell.\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função auxiliar para carregar as imagens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essa função carrega alguns arquivos de imagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_images(image_paths):\n",
    "    # Load the images from disk.\n",
    "    images = [imread(path) for path in image_paths]\n",
    "\n",
    "    # Convert to a numpy array and return it.\n",
    "    return np.asarray(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the first images from the test-set.\n",
    "images = load_images(image_paths=image_paths_test[0:9])\n",
    "\n",
    "# Get the true classes for those images.\n",
    "cls_true = cls_test[0:9]\n",
    "\n",
    "# Plot the images and labels using our helper-function above.\n",
    "plot_images(images=images, cls_true=cls_true, smooth=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download do Modelo Inception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inception.maybe_download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Carregar o Modelo Inception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = inception.Inception()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calcular Valores de Transferência"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importar uma função auxiliar para manter os valores de transferência do modelo inception em cache."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inception import transfer_values_cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setar os caminhos para armazenar os dados de treino e de teste em cache (arquivo plk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_cache_train = os.path.join(data_dir, 'inception-tcc-train.pkl')\n",
    "file_path_cache_test = os.path.join(data_dir, 'inception-tcc-test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Processing Inception transfer-values for training-images ...\")\n",
    "\n",
    "# If transfer-values have already been calculated then reload them,\n",
    "# otherwise calculate them and save them to a cache-file.\n",
    "transfer_values_train = transfer_values_cache(cache_path=file_path_cache_train,\n",
    "                                              image_paths=image_paths_train,\n",
    "                                              model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Processing Inception transfer-values for test-images ...\")\n",
    "\n",
    "# If transfer-values have already been calculated then reload them,\n",
    "# otherwise calculate them and save them to a cache-file.\n",
    "transfer_values_test = transfer_values_cache(cache_path=file_path_cache_test,\n",
    "                                             image_paths=image_paths_test,\n",
    "                                             model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Dimensão dos valores de transferência"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train:')\n",
    "transfer_values_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test:')\n",
    "transfer_values_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Função Auxiliar para visualização dos valores de transferência"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_transfer_values(i):\n",
    "    print(\"Input image:\")\n",
    "    \n",
    "    # Plot the i'th image from the test-set.\n",
    "    image = imread(image_paths_test[i])\n",
    "    plt.imshow(image, interpolation='spline16')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Transfer-values for the image using Inception model:\")\n",
    "    \n",
    "    # Transform the transfer-values into an image.\n",
    "    img = transfer_values_test[i]\n",
    "    img = img.reshape((32, 64))\n",
    "\n",
    "    # Plot the image for the transfer-values.\n",
    "    plt.imshow(img, interpolation='nearest', cmap='Reds')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Visualização dos valores de transferência de duas imagens do conjunto de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_transfer_values(i=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_transfer_values(i=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analise dos valores de transferência usando PCA \n",
    "--- Principal Component Analysis---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_values = transfer_values_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = cls_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_values_reduced = pca.fit_transform(transfer_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_values_reduced.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Função Auxiliar para mostrar a redução dos valores de transferencia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scatter(values, cls):\n",
    "    # Create a color-map with a different color for each class.\n",
    "    import matplotlib.cm as cm\n",
    "    cmap = cm.rainbow(np.linspace(0.0, 1.0, num_classes))\n",
    "\n",
    "    # Create an index with a random permutation to make a better plot.\n",
    "    idx = np.random.permutation(len(values))\n",
    "    \n",
    "    # Get the color for each sample.\n",
    "    colors = cmap[cls[idx]]\n",
    "\n",
    "    # Extract the x- and y-values.\n",
    "    x = values[idx, 0]\n",
    "    y = values[idx, 1]\n",
    "\n",
    "    # Plot it.\n",
    "    print('Matplotlib Graphic:')\n",
    "    plt.scatter(x, y, color=colors, alpha=0.5)\n",
    "    print('Seaborn Graphic:')\n",
    "    g = sn.jointplot(x, y, kind='reg', scatter = False )\n",
    "    g.ax_joint.scatter(x,y, c=colors)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scatter(transfer_values_reduced,cls=cls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analise dos valores de transformação usando t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=50)\n",
    "transfer_values_50d = pca.fit_transform(transfer_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_values_reduced = tsne.fit_transform(transfer_values_50d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_values_reduced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scatter(transfer_values_reduced,cls=cls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir dos resultados vistos nos gráficos acima é possível determinar que o modelo poderá ser treinado para obter resultados satisfatórios, visto que conseguimos separar as imagens em clusters bem definidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Novo Classificador em Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definição dos logs de treino, validação e teste para acompanhamento via Tensorboard\n",
    "log_writer_train = SummaryWriter('logs_ft/train/')\n",
    "log_writer_val = SummaryWriter('logs_ft/val/')\n",
    "#log_writer_test = SummaryWriter('logs/test/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalização dos dados para treinamento\n",
    "# Normalização para a etapa de validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data/dataset'\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'val']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "              for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "\n",
    "\n",
    "# Get a batch of training data\n",
    "inputs, classes = next(iter(dataloaders['train']))\n",
    "\n",
    "# Make a grid from batch\n",
    "out = torchvision.utils.make_grid(inputs)\n",
    "\n",
    "imshow(out, title=[class_names[x] for x in classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                log_writer_train.add_scalar('Loss',float(epoch_loss), epoch+1)\n",
    "                log_writer_train.add_scalar('Accuracy', float(epoch_acc), epoch+1)\n",
    "            elif phase =='val':\n",
    "                log_writer_val.add_scalar('Loss',float(epoch_loss), epoch+1)\n",
    "                log_writer_val.add_scalar('Accuracy', float(epoch_acc), epoch+1)\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        \n",
    "        print()\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_model(model, num_images=6):\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "    images_so_far = 0\n",
    "    fig = plt.figure()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(dataloaders['val']):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            for j in range(inputs.size()[0]):\n",
    "                images_so_far += 1\n",
    "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
    "                ax.axis('off')\n",
    "                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n",
    "                imshow(inputs.cpu().data[j])\n",
    "\n",
    "                if images_so_far == num_images:\n",
    "                    model.train(mode=was_training)\n",
    "                    return\n",
    "        model.train(mode=was_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = models.inception_v3(pretrained=True)\n",
    "model_ft.aux_logits=False\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "# Here the size of each output sample is set to 2.\n",
    "# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
    "model_ft.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 5 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=5, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = train_model(model_ft, criterion, optimizer_ft,\n",
    "                         exp_lr_scheduler, num_epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_model(model_ft)\n",
    "\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Salvar o Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_ft, 'prediction_ft_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Add o graph no Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Inferência sobre o modelo criado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=torch.load('prediction_ft_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image_path):\n",
    "    # Load Image\n",
    "    img = Imagem.open(image_path)\n",
    "    \n",
    "    # Get the dimensions of the image\n",
    "    width, height = img.size\n",
    "    \n",
    "    # Resize by keeping the aspect ratio, but changing the dimension\n",
    "    # so the shortest size is 255px\n",
    "    img = img.resize((255, int(255*(height/width))) if width < height else (int(255*(width/height)), 255))\n",
    "    \n",
    "    # Get the dimensions of the new image size\n",
    "    width, height = img.size\n",
    "    \n",
    "    # Set the coordinates to do a center crop of 224 x 224\n",
    "    left = (width - 224)/2\n",
    "    top = (height - 224)/2\n",
    "    right = (width + 224)/2\n",
    "    bottom = (height + 224)/2\n",
    "    img = img.crop((left, top, right, bottom))\n",
    "    \n",
    "    # Turn image into numpy array\n",
    "    img = np.array(img)\n",
    "    \n",
    "    # Make the color channel dimension first instead of last\n",
    "    img = img.transpose((2, 0, 1))\n",
    "    \n",
    "    # Make all values between 0 and 1\n",
    "    img = img/255\n",
    "    \n",
    "    # Normalize based on the preset mean and standard deviation\n",
    "    img[0] = (img[0] - 0.485)/0.229\n",
    "    img[1] = (img[1] - 0.456)/0.224\n",
    "    img[2] = (img[2] - 0.406)/0.225\n",
    "    \n",
    "    # Add a fourth dimension to the beginning to indicate batch size\n",
    "    img = img[np.newaxis,:]\n",
    "    \n",
    "    # Turn into a torch tensor\n",
    "    image = torch.from_numpy(img)\n",
    "    image = image.float()\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(image, model):\n",
    "    # Pass the image through our model\n",
    "    output = model.forward(image)\n",
    "    \n",
    "    # Reverse the log function in our output\n",
    "    output = torch.exp(output)\n",
    "    \n",
    "    # Get the top predicted class, and the output percentage for\n",
    "    # that class\n",
    "    probs, classes = output.topk(1, dim=1)\n",
    "    return probs.item(), classes.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show Image\n",
    "def show_image(image):\n",
    "    # Convert image to numpy\n",
    "    image = image.numpy()\n",
    "    \n",
    "    # Un-normalize the image\n",
    "    image[0] = image[0] * 0.226 + 0.445\n",
    "    \n",
    "    # Print the image\n",
    "    fig = plt.figure(figsize=(25, 4))\n",
    "    plt.imshow(np.transpose(image[0], (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = process_image(\"20191103_142524.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_prob, top_class = predict(image, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show_image(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Classe: ',class_names[top_class]  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir_infer = './data/dataset/val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_images(num):\n",
    "    data = datasets.ImageFolder(data_dir_infer, transform=test_transforms)\n",
    "    classes = data.classes\n",
    "    indices = list(range(len(data)))\n",
    "    np.random.shuffle(indices)\n",
    "    idx = indices[:num]\n",
    "    from torch.utils.data.sampler import SubsetRandomSampler\n",
    "    sampler = SubsetRandomSampler(idx)\n",
    "    loader = torch.utils.data.DataLoader(data, \n",
    "                   sampler=sampler, batch_size=num)\n",
    "    dataiter = iter(loader)\n",
    "    images, labels = dataiter.next()\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transforms = transforms.Compose([transforms.Resize(224),\n",
    "                                      transforms.ToTensor(),\n",
    "                                     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = get_random_images(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('./logs_ft')\n",
    "writer.add_graph(model_ft, images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('./data/dataset/test/conformes')\n",
    "conformes = os.listdir('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_conforme=[]\n",
    "for conf in conformes:\n",
    "    image = process_image(conf)\n",
    "    top_prob, top_class = predict(image, model)\n",
    "    pred_conforme.append(top_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_conforme_in_conforme=0\n",
    "cont_n_conforme_in_conforme=0\n",
    "for i in pred_conforme:\n",
    "    if i == 0:\n",
    "        cont_conforme_in_conforme+=1\n",
    "    else:\n",
    "        cont_n_conforme_in_conforme+=1\n",
    "print('conformes em conformes:',cont_conforme_in_conforme)\n",
    "print('não conformes em conformes:',cont_n_conforme_in_conforme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../nao-conformes')\n",
    "nao_conformes = os.listdir('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_n_conforme=[]\n",
    "for nconf in nao_conformes:\n",
    "    image = process_image(nconf)\n",
    "    top_prob, top_class = predict(image, model)\n",
    "    pred_n_conforme.append(top_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_nconforme_in_nconforme=0\n",
    "cont_conforme_in_nconforme=0\n",
    "for i in pred_n_conforme:\n",
    "    if i == 1:\n",
    "        cont_nconforme_in_nconforme+=1\n",
    "    else:\n",
    "        cont_conforme_in_nconforme+=1\n",
    "print('não-conformes em não-conformes:',cont_nconforme_in_nconforme)\n",
    "print('conformes em não-conformes:',cont_conforme_in_nconforme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = [[cont_conforme_in_conforme,cont_n_conforme_in_conforme],\n",
    "         [cont_conforme_in_nconforme,cont_nconforme_in_nconforme]]        \n",
    "df_cm = pd.DataFrame(array)\n",
    "f, ax = plt.subplots(figsize=(9, 6))\n",
    "sn.set()\n",
    "sn.heatmap(df_cm, annot=True,linewidths=.5,fmt=\"d\",ax=ax, cmap='cool')\n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
    "ax.set_title('Confusion Matrix'); \n",
    "ax.xaxis.set_ticklabels(['Conformes', 'Não-Conformes'],va=\"center\"); ax.yaxis.set_ticklabels(['Conformes', 'Não-Conformes'],va=\"center\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_test=[]\n",
    "nconf_test=[]\n",
    "for i in range(len(pred_conforme)):\n",
    "    conf_test.append(0)\n",
    "for i in range(len(pred_n_conforme)):\n",
    "    nconf_test.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(conf_test,pred_conforme))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(nconf_test,pred_n_conforme))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
